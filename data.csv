import apache_beam as beam
from apache_beam.options.pipeline_options import PipelineOptions
from apache_beam.io import ReadFromParquet, WriteToText
import json
import random

# Define the default values
default_values = {
    "ipi": 24.0,
    "lpq": 1.0,
    "tot_ord": 7,
    "id": "155024682",
    "g1": 0.15842,
    "pb1": 0.15842,
    "qP": 1,
    "src": 1,
    "bvId": "155024682",
    "ptc": "PT1323014",
    "lpd": "20240707",
    "b1": 0.15842,
    "g2": 0.15839,
    "ipi1": 16.75,
    "g3": 0.070629999
}

def generate_items(prod_id_list):
    items = []
    for prod_id in prod_id_list:
        item = {
            "ipi": default_values["ipi"],
            "lpq": default_values["lpq"],
            "tot_ord": default_values["tot_ord"],
            "id": default_values["id"],
            "g1": default_values["g1"],
            "pb1": default_values["pb1"],
            "qP": default_values["qP"],
            "p": prod_id,
            "src": default_values["src"],
            "bvId": default_values["bvId"],
            "ptc": default_values["ptc"],
            "lpd": default_values["lpd"],
            "b1": default_values["b1"],
            "g2": default_values["g2"],
            "ipi1": default_values["ipi1"],
            "g3": default_values["g3"]
        }
        items.append(item)
    return items

def process_element(element):
    membership_nbr = element['membership_nbr']
    prod_id = element['prod_id']
    cid = random.randint(1, 1000000)
    prod_id_list = prod_id.split(',')
    items = generate_items(prod_id_list)
    result = {
        "CID": cid,
        "data": {
            "pbs": 1,
            "ts": 1720602704,
            "cid": str(cid),
            "ct": 3,
            "items": items
        }
    }
    return result

def format_json(element):
    return json.dumps(element, indent=4)

def format_with_commas(elements):
    result = []
    for i, element in enumerate(elements):
        if i < len(elements) - 1:
            result.append(element + ',')
        else:
            result.append(element)
    return result

# Define the pipeline options
pipeline_options = PipelineOptions()

# Path to the input Parquet file
input_parquet_path = '/home/jovyan/bindhu/harmony/rye_reco_2024-06-22_part-000000000000.parquet'

# Create the pipeline
with beam.Pipeline(options=pipeline_options) as p:
    json_lines = (
        p
        | 'Read from Parquet' >> ReadFromParquet(input_parquet_path)
        | 'Process Elements' >> beam.Map(process_element)
        | 'Format as JSON' >> beam.Map(format_json)
        | 'Add Commas' >> beam.combiners.ToList()
        | 'Format with Commas' >> beam.FlatMap(format_with_commas)
        | 'Write to File' >> WriteToText('output1.json', num_shards=1, shard_name_template='', append_trailing_newlines=False)
    )













import apache_beam as beam
from apache_beam.options.pipeline_options import PipelineOptions, GoogleCloudOptions, StandardOptions
from apache_beam.io.parquetio import ReadFromParquet
from apache_beam.io import WriteToText
import json
import random

class ProcessElement(beam.DoFn):
    default_values = {
        "ipi": 24.0,
        "lpq": 1.0,
        "tot_ord": 7,
        "id": "155024682",
        "g1": 0.15842,
        "pb1": 0.15842,
        "qP": 1,
        "src": 1,
        "bvId": "155024682",
        "ptc": "PT1323014",
        "lpd": "20240707",
        "b1": 0.15842,
        "g2": 0.15839,
        "ipi1": 16.75,
        "g3": 0.070629999
    }

    def generate_items(self, prod_id_list):
        items = []
        for prod_id in prod_id_list:
            item = {
                "ipi": self.default_values["ipi"],
                "lpq": self.default_values["lpq"],
                "tot_ord": self.default_values["tot_ord"],
                "id": self.default_values["id"],
                "g1": self.default_values["g1"],
                "pb1": self.default_values["pb1"],
                "qP": self.default_values["qP"],
                "p": prod_id,
                "src": self.default_values["src"],
                "bvId": self.default_values["bvId"],
                "ptc": self.default_values["ptc"],
                "lpd": self.default_values["lpd"],
                "b1": self.default_values["b1"],
                "g2": self.default_values["g2"],
                "ipi1": self.default_values["ipi1"],
                "g3": self.default_values["g3"]
            }
            items.append(item)
        return items

    def process(self, element):
        import random
        membership_nbr = element['membership_nbr']
        prod_id = element['prod_id']
        cid = random.randint(1, 1000000)
        prod_id_list = prod_id.split(',')
        items = self.generate_items(prod_id_list)
        result = {
            "CID": cid,
            "data": {
                "pbs": 1,
                "ts": 1720602704,
                "ct": 3,
                "items": items
            }
        }
        yield result

def format_json(element):
    return json.dumps(element, indent=4)

def format_with_commas(elements):
    result = []
    for i, element in enumerate(elements):
        if i < len(elements) - 1:
            result.append(element + ',')
        else:
            result.append(element)
    return result

# Define the pipeline options
pipeline_options = PipelineOptions()
google_cloud_options = pipeline_options.view_as(GoogleCloudOptions)
google_cloud_options.project = 'playground-s-11-27ec8fa8'
google_cloud_options.job_name = 'parquet-to-json'
google_cloud_options.staging_location = 'gs://shuvabuc007/staging'
google_cloud_options.temp_location = 'gs://shuvabuc007/temp'
pipeline_options.view_as(StandardOptions).runner = 'DataflowRunner'
pipeline_options.view_as(GoogleCloudOptions).region = 'us-central1'

# Path to the input Parquet file in GCS
input_parquet_path = 'gs://shuvabuc007/input/part-00000-c7585b4f-7e43-4685-ad20-ebdb71ca97a6-c000.snappy.parquet'

# Path to the output JSON file in GCS
output_json_path = 'gs://shuvabuc007/output/output.json'

# Create the pipeline
with beam.Pipeline(options=pipeline_options) as p:
    json_lines = (
        p
        | 'Read from Parquet' >> ReadFromParquet(input_parquet_path)
        | 'Process Elements' >> beam.ParDo(ProcessElement())
        | 'Format as JSON' >> beam.Map(format_json)
        | 'Add Commas' >> beam.combiners.ToList()
        | 'Format with Commas' >> beam.FlatMap(format_with_commas)
        | 'Write to File' >> WriteToText(output_json_path, num_shards=1, shard_name_template='', append_trailing_newlines=False)
    )
